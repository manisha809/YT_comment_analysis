{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP_J2ih6eaGA",
        "outputId": "3d1fda17-369c-4e4f-f24c-3b502e0a2d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    sentiment_scores = sid.polarity_scores(text)\n",
        "\n",
        "    # Interpret the sentiment score\n",
        "    if sentiment_scores['compound'] >= 0.05:\n",
        "        return 'positive'\n",
        "    elif sentiment_scores['compound'] <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your_other_script.py\n",
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        " # Import the sentiment analysis function\n",
        "\n",
        "# API key and YouTube Data API service\n",
        "API_KEY = \"AIzaSyD74cfUIsVfvXlfnuSVV7sg_cwulqehRMc\"\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "# Define functions for sentiment analysis and model prediction\n",
        "def get_sentiment(comment):\n",
        "    return analyze_sentiment(comment)  # Use the sentiment analysis function\n",
        "\n",
        "def predict_sentiment(video_id):\n",
        "    # Fetch comments\n",
        "    comments_list = []\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        request = (\n",
        "            youtube.commentThreads()\n",
        "            .list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video_id,\n",
        "                maxResults=100,\n",
        "                pageToken=next_page_token,\n",
        "            )\n",
        "            .execute()\n",
        "        )\n",
        "        # Use the correct key for comment text\n",
        "        comments_list += [c[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"] for c in request[\"items\"]]\n",
        "        next_page_token = request.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    # Predict sentiment using sentiment analysis function\n",
        "    predicted_sentiments = [analyze_sentiment(comment) for comment in comments_list]\n",
        "\n",
        "    # Count and calculate percentages\n",
        "    positive_count = sum(sentiment == 'positive' for sentiment in predicted_sentiments)\n",
        "    negative_count = sum(sentiment == 'negative' for sentiment in predicted_sentiments)\n",
        "    neutral_count = sum(sentiment == 'neutral' for sentiment in predicted_sentiments)\n",
        "    total_count = len(comments_list)\n",
        "    positive_percentage = (positive_count / total_count) * 100\n",
        "    negative_percentage = (negative_count / total_count) * 100\n",
        "    neutral_percentage = (neutral_count / total_count) * 100\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        \"positive_percentage\": positive_percentage,\n",
        "        \"negative_percentage\": negative_percentage,\n",
        "        \"neutral_percentage\": neutral_percentage,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "6iAUikWGfwOA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "video_id = \"Dydmpfo68DA\"\n",
        "results = predict_sentiment(video_id)\n",
        "\n",
        "print(f\"Positive comments: {results['positive_percentage']:.2f}%\")\n",
        "print(f\"Negative comments: {results['negative_percentage']:.2f}%\")\n",
        "print(f\"Neutral comments: {results['neutral_percentage']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLWINlXCf_Hs",
        "outputId": "9432026a-6a00-4ffb-9eb0-81c5b2116557"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive comments: 29.45%\n",
            "Negative comments: 12.00%\n",
            "Neutral comments: 58.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y3M5QEL-gi3D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}